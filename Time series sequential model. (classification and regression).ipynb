{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df435a6e",
   "metadata": {},
   "source": [
    "# Time series sequential model (LSTM): classification and regression\n",
    "\n",
    "This notebook provides a clean, end-to-end workflow for training **LSTM** models on county-level annual hydroclimate features and predicting **damage outcomes**.\n",
    "\n",
    "We include two modeling strategies:\n",
    "\n",
    "1. **Single-stage regression** (baseline): predict `log1p(damage)` directly.\n",
    "2. **Two-part (hurdle) model** (recommended for zero-inflated damages):\n",
    "   - **Classifier**: predict whether damage occurs (`damage > 0`).\n",
    "   - **Regressor**: predict magnitude conditional on damage occurring (trained on positive-damage years only).\n",
    "   - Final prediction: \\(\\hat D = P(D>0)\\times E[D\\mid D>0]\\)\n",
    "\n",
    "**Inputs (CSV):**\n",
    "- `flood_model_table_clean_1996_2023.csv`\n",
    "- `drought_model_table_clean_1996_2023.csv`\n",
    "- `climate_for_LSTM_1996_2059.csv` (for future projections)\n",
    "\n",
    "> **Note:** Paths are configured in the **Configuration** cell. Update `BASE` to your local directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e6333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Configuration\n",
    "# -------------------------\n",
    "import os\n",
    "\n",
    "# Update to your local folder\n",
    "BASE = r\"C:\\Users\\adi10136\\OneDrive - Iowa State University\\CMIP6_Data\\CMIP6_NEW\"\n",
    "\n",
    "FLOOD_HIST_CSV   = os.path.join(BASE, \"flood_model_table_clean_1996_2023.csv\")\n",
    "DROUGHT_HIST_CSV = os.path.join(BASE, \"drought_model_table_clean_1996_2023.csv\")\n",
    "CLIMATE_FUTURE_CSV = os.path.join(BASE, \"climate_for_LSTM_1996_2059.csv\")\n",
    "\n",
    "SEQ_LEN = 5  # sequence/window length (years); must match training & prediction\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Imports & reproducibility\n",
    "# -------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Optional for plots/diagnostics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.keras.utils.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Load historical tables\n",
    "# -------------------------\n",
    "flood_df = pd.read_csv(FLOOD_HIST_CSV)\n",
    "drought_df = pd.read_csv(DROUGHT_HIST_CSV)\n",
    "\n",
    "display(flood_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323cb29c",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "Each historical table is expected to include (at minimum) the following columns:\n",
    "\n",
    "- `county`\n",
    "- `year`\n",
    "- `precip_ann` (annual precipitation)\n",
    "- `runoff_ann` (annual runoff)\n",
    "- `damage_property`\n",
    "- `damage_crops`\n",
    "\n",
    "The workflow builds sliding windows of length `SEQ_LEN` for each county, using `[precip_ann, runoff_ann]` as the model inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d91c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_error_and_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Percent error on TOTAL:\n",
    "      PE = 100 * (pred_sum - obs_sum) / obs_sum\n",
    "    Accuracy = 100 - |PE|\n",
    "    \"\"\"\n",
    "    obs_sum = float(np.sum(y_true))\n",
    "    pred_sum = float(np.sum(y_pred))\n",
    "    if obs_sum == 0:\n",
    "        return np.nan, np.nan\n",
    "    pe = 100.0 * (pred_sum - obs_sum) / obs_sum\n",
    "    acc = 100.0 - abs(pe)\n",
    "    return pe, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac70ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequences_from_table(df, seq_len=5):\n",
    "    \"\"\"\n",
    "    df columns:\n",
    "      county, year, precip_ann, runoff_ann, damage_property, damage_crops\n",
    "\n",
    "    Returns:\n",
    "      X       : (N_samples, seq_len, 2)   [precip, runoff]\n",
    "      y_prop  : (N_samples,)              property damage\n",
    "      y_crops : (N_samples,)              crops damage\n",
    "      meta    : DataFrame with ['county', 'year'] per sample (target year)\n",
    "    \"\"\"\n",
    "    df = df.sort_values([\"county\", \"year\"]).copy()\n",
    "\n",
    "    df[\"precip_ann\"] = pd.to_numeric(df[\"precip_ann\"], errors=\"coerce\")\n",
    "    df[\"runoff_ann\"] = pd.to_numeric(df[\"runoff_ann\"], errors=\"coerce\")\n",
    "    df[\"damage_property\"] = pd.to_numeric(df[\"damage_property\"], errors=\"coerce\").fillna(0.0)\n",
    "    df[\"damage_crops\"]    = pd.to_numeric(df[\"damage_crops\"], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    X_list = []\n",
    "    y_p_list = []\n",
    "    y_c_list = []\n",
    "    meta_rows = []\n",
    "\n",
    "    for county, g in df.groupby(\"county\"):\n",
    "        g = g.sort_values(\"year\").reset_index(drop=True)\n",
    "\n",
    "        if len(g) < seq_len:\n",
    "            continue\n",
    "\n",
    "        for end_idx in range(seq_len - 1, len(g)):\n",
    "            start_idx = end_idx - seq_len + 1\n",
    "            window = g.iloc[start_idx:end_idx+1]\n",
    "\n",
    "            if window[\"precip_ann\"].isna().any() or window[\"runoff_ann\"].isna().any():\n",
    "                continue\n",
    "\n",
    "            X_win = window[[\"precip_ann\", \"runoff_ann\"]].values.astype(float)\n",
    "            y_prop = float(g.iloc[end_idx][\"damage_property\"])\n",
    "            y_crops = float(g.iloc[end_idx][\"damage_crops\"])\n",
    "            year_t = int(g.iloc[end_idx][\"year\"])\n",
    "\n",
    "            X_list.append(X_win)\n",
    "            y_p_list.append(y_prop)\n",
    "            y_c_list.append(y_crops)\n",
    "            meta_rows.append({\"county\": county, \"year\": year_t})\n",
    "\n",
    "    if not X_list:\n",
    "        raise ValueError(\"No sequences constructed. Check seq_len and data.\")\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y_p = np.array(y_p_list, dtype=float)\n",
    "    y_c = np.array(y_c_list, dtype=float)\n",
    "    meta = pd.DataFrame(meta_rows)\n",
    "\n",
    "    return X, y_p, y_c, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce51ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Build sequences for flood / drought\n",
    "# -------------------------\n",
    "X_flood, y_p_flood, y_c_flood, meta_flood = build_sequences_from_table(flood_df, seq_len=SEQ_LEN)\n",
    "X_drought, y_p_drought, y_c_drought, meta_drought = build_sequences_from_table(drought_df, seq_len=SEQ_LEN)\n",
    "\n",
    "print(\"FLOOD sequences:\", X_flood.shape, \"| target years:\", meta_flood[\"year\"].min(), \"-\", meta_flood[\"year\"].max())\n",
    "print(\"DROUGHT sequences:\", X_drought.shape, \"| target years:\", meta_drought[\"year\"].min(), \"-\", meta_drought[\"year\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87564cc",
   "metadata": {},
   "source": [
    "## Baseline: single-stage regression LSTM\n",
    "\n",
    "We predict `log1p(damage)` to stabilize variance and reduce sensitivity to outliers:\n",
    "\n",
    "- Train on all samples (including zeros).\n",
    "- Back-transform with `expm1()` for interpretation in dollars.\n",
    "\n",
    "The metric below reports **percent error on the total** across the test split:\n",
    "\\[\n",
    "PE = 100\\times\\frac{\\sum\\hat y - \\sum y}{\\sum y}\n",
    "\\]\n",
    "and **Accuracy** is defined as \\(100-|PE|\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5091190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(seq_len, n_features=2):\n",
    "    \"\"\"\n",
    "    LSTM for regression on log1p(damage).\n",
    "    Input:  (seq_len, n_features)\n",
    "    Output: scalar (log1p(damage))\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(seq_len, n_features))\n",
    "    x = layers.LSTM(32, return_sequences=False)(inputs)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"mse\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_lstm_for_target(X, y_raw,\n",
    "                          test_size=0.2,\n",
    "                          n_epochs=50,\n",
    "                          batch_size=32,\n",
    "                          random_state=42,\n",
    "                          verbose=1):\n",
    "    \"\"\"\n",
    "    Train LSTM for ONE target (property or crops).\n",
    "\n",
    "    X: (N, seq_len, 2)\n",
    "    y_raw: (N,) damage in dollars\n",
    "    \"\"\"\n",
    "    y_log = np.log1p(y_raw)\n",
    "\n",
    "    # scale features\n",
    "    N, T, F = X.shape\n",
    "    X_flat = X.reshape(N * T, F)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_flat_scaled = scaler.fit_transform(X_flat)\n",
    "    X_scaled = X_flat_scaled.reshape(N, T, F)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y_log, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    seq_len = X.shape[1]\n",
    "    model = build_lstm_model(seq_len=seq_len, n_features=F)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=n_epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    # predict\n",
    "    y_pred_log = model.predict(X_test).ravel()\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_true = np.expm1(y_test)\n",
    "\n",
    "    pe, acc = percent_error_and_accuracy(y_true, y_pred)\n",
    "\n",
    "    return model, scaler, (y_true, y_pred, pe, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a430f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Flood baseline regression\n",
    "# -------------------------\n",
    "print(\"Training baseline LSTM (regression) — FLOOD property\")\n",
    "flood_prop_model, flood_prop_scaler, (yt_p, yp_p, pe_p, acc_p) = train_lstm_for_target(\n",
    "    X_flood, y_p_flood,\n",
    "    test_size=0.2, n_epochs=50, batch_size=32,\n",
    "    random_state=123, verbose=1\n",
    ")\n",
    "print(\"FLOOD property — percent error:\", pe_p, \" | accuracy:\", acc_p)\n",
    "\n",
    "print(\"\\nTraining baseline LSTM (regression) — FLOOD crops\")\n",
    "flood_crops_model, flood_crops_scaler, (yt_c, yp_c, pe_c, acc_c) = train_lstm_for_target(\n",
    "    X_flood, y_c_flood,\n",
    "    test_size=0.2, n_epochs=100, batch_size=32,\n",
    "    random_state=456, verbose=1\n",
    ")\n",
    "print(\"FLOOD crops — percent error:\", pe_c, \" | accuracy:\", acc_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd77192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick diagnostic plot (baseline regression, FLOOD property)\n",
    "plt.figure()\n",
    "plt.scatter(yt_p, yp_p, s=10)\n",
    "plt.xlabel(\"True damage (property)\")\n",
    "plt.ylabel(\"Predicted damage (property)\")\n",
    "plt.title(\"Baseline LSTM regression — FLOOD property (test split)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c227bbe",
   "metadata": {},
   "source": [
    "## Two-part model: classification + regression (recommended)\n",
    "\n",
    "Damages are often **zero-inflated** (many county-years have zero loss).  \n",
    "A two-part model explicitly separates:\n",
    "\n",
    "1) **Occurrence**: `damage > 0` (binary classification)  \n",
    "2) **Magnitude**: predict `log1p(damage)` on **positive-damage** samples only\n",
    "\n",
    "Final prediction: \\(\\hat D = p\\times \\mu\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_classifier(seq_len, n_features=2):\n",
    "    inputs = layers.Input(shape=(seq_len, n_features))\n",
    "    x = layers.LSTM(32, return_sequences=False)(inputs)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)  # probability\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_lstm_classifier(X, y_raw,\n",
    "                          test_size=0.2,\n",
    "                          n_epochs=40,\n",
    "                          batch_size=32,\n",
    "                          random_state=42,\n",
    "                          verbose=1):\n",
    "    \"\"\"\n",
    "    y_raw: damage in dollars; we convert to 0/1.\n",
    "    \"\"\"\n",
    "    y_bin = (y_raw > 0).astype(int)\n",
    "\n",
    "    # scale X\n",
    "    N, T, F = X.shape\n",
    "    X_flat = X.reshape(N * T, F)\n",
    "    scaler = StandardScaler()\n",
    "    X_flat_scaled = scaler.fit_transform(X_flat)\n",
    "    X_scaled = X_flat_scaled.reshape(N, T, F)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y_bin, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    seq_len = X.shape[1]\n",
    "    model = build_lstm_classifier(seq_len=seq_len, n_features=F)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=n_epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    # predicted probabilities on test\n",
    "    p_test = model.predict(X_test).ravel()\n",
    "\n",
    "    return model, scaler, (y_test, p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be6c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_regressor_positive(X, y_raw,\n",
    "                                  test_size=0.2,\n",
    "                                  n_epochs=50,\n",
    "                                  batch_size=32,\n",
    "                                  random_state=42,\n",
    "                                  verbose=1):\n",
    "    \"\"\"\n",
    "    Train LSTM regressor ONLY on positive damage years.\n",
    "    \"\"\"\n",
    "    mask_pos = y_raw > 0\n",
    "    X_pos = X[mask_pos]\n",
    "    y_pos = y_raw[mask_pos]\n",
    "\n",
    "    if X_pos.shape[0] < 10:\n",
    "        raise ValueError(\"Too few positive samples to train regressor.\")\n",
    "\n",
    "    y_log = np.log1p(y_pos)\n",
    "\n",
    "    # scale features\n",
    "    N, T, F = X_pos.shape\n",
    "    X_flat = X_pos.reshape(N * T, F)\n",
    "    scaler = StandardScaler()\n",
    "    X_flat_scaled = scaler.fit_transform(X_flat)\n",
    "    X_scaled = X_flat_scaled.reshape(N, T, F)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y_log, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    seq_len = X_pos.shape[1]\n",
    "    model = build_lstm_model(seq_len=seq_len, n_features=F)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=n_epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    y_pred_log = model.predict(X_test).ravel()\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_true = np.expm1(y_test)\n",
    "\n",
    "    pe, acc = percent_error_and_accuracy(y_true, y_pred)\n",
    "\n",
    "    return model, scaler, (y_true, y_pred, pe, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf79746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_two_part_lstm(X, y_raw,\n",
    "                           clf_model, clf_scaler,\n",
    "                           reg_model, reg_scaler):\n",
    "    \"\"\"\n",
    "    Compute two-part LSTM prediction and overall accuracy for ALL samples:\n",
    "      D_hat = P(damage>0) * E[damage | damage>0]\n",
    "\n",
    "    X: (N, seq_len, 2)\n",
    "    y_raw: (N,) true damage in dollars\n",
    "    \"\"\"\n",
    "    N, T, F = X.shape\n",
    "\n",
    "    # --- classifier branch ---\n",
    "    X_flat = X.reshape(N * T, F)\n",
    "    X_flat_clf = clf_scaler.transform(X_flat)\n",
    "    X_scaled_clf = X_flat_clf.reshape(N, T, F)\n",
    "\n",
    "    p_pos_all = clf_model.predict(X_scaled_clf).ravel()  # P(damage>0)\n",
    "\n",
    "    # --- regressor branch ---\n",
    "    X_flat_reg = reg_scaler.transform(X_flat)\n",
    "    X_scaled_reg = X_flat_reg.reshape(N, T, F)\n",
    "\n",
    "    mu_log_all = reg_model.predict(X_scaled_reg).ravel()\n",
    "    mu_all = np.expm1(mu_log_all)\n",
    "    mu_all = np.clip(mu_all, 0, None)\n",
    "\n",
    "    # --- two-part prediction ---\n",
    "    y_pred = p_pos_all * mu_all\n",
    "    y_true = y_raw\n",
    "\n",
    "    pe, acc = percent_error_and_accuracy(y_true, y_pred)\n",
    "    return y_true, y_pred, pe, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9414ef79",
   "metadata": {},
   "source": [
    "### Train and evaluate two-part models (Flood, Drought; Property, Crops)\n",
    "\n",
    "For each target variable:\n",
    "- Train classifier on all samples\n",
    "- Train regressor on positive years only\n",
    "- Evaluate combined two-part prediction on all samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25178b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# FLOOD — property (two-part)\n",
    "# -------------------------\n",
    "print(\"FLOOD property — classifier\")\n",
    "clf_flood_prop_model, clf_flood_prop_scaler, (y_bin_fp_test, p_fp_test) = train_lstm_classifier(\n",
    "    X_flood, y_p_flood,\n",
    "    test_size=0.3, n_epochs=50, batch_size=5,\n",
    "    random_state=123, verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nFLOOD property — regressor (positive years only)\")\n",
    "reg_flood_prop_model, reg_flood_prop_scaler, (yt_fp_pos, yp_fp_pos, pe_fp_pos, acc_fp_pos) = train_lstm_regressor_positive(\n",
    "    X_flood, y_p_flood,\n",
    "    test_size=0.3, n_epochs=100, batch_size=5,\n",
    "    random_state=123, verbose=1\n",
    ")\n",
    "print(\"FLOOD property positive-years — percent error:\", pe_fp_pos, \" | accuracy:\", acc_fp_pos)\n",
    "\n",
    "y_true_fp, y_pred_fp, pe_fp_all, acc_fp_all = evaluate_two_part_lstm(\n",
    "    X_flood, y_p_flood,\n",
    "    clf_flood_prop_model, clf_flood_prop_scaler,\n",
    "    reg_flood_prop_model, reg_flood_prop_scaler\n",
    ")\n",
    "print(\"\\nFLOOD property (two-part, all years) — percent error:\", pe_fp_all, \" | accuracy:\", acc_fp_all)\n",
    "\n",
    "# -------------------------\n",
    "# FLOOD — crops (two-part)\n",
    "# -------------------------\n",
    "print(\"\\nFLOOD crops — classifier\")\n",
    "clf_flood_crops_model, clf_flood_crops_scaler, (y_bin_fc_test, p_fc_test) = train_lstm_classifier(\n",
    "    X_flood, y_c_flood,\n",
    "    test_size=0.3, n_epochs=220, batch_size=3,\n",
    "    random_state=456, verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nFLOOD crops — regressor (positive years only)\")\n",
    "reg_flood_crops_model, reg_flood_crops_scaler, (yt_fc_pos, yp_fc_pos, pe_fc_pos, acc_fc_pos) = train_lstm_regressor_positive(\n",
    "    X_flood, y_c_flood,\n",
    "    test_size=0.3, n_epochs=100, batch_size=3,\n",
    "    random_state=456, verbose=1\n",
    ")\n",
    "print(\"FLOOD crops positive-years — percent error:\", pe_fc_pos, \" | accuracy:\", acc_fc_pos)\n",
    "\n",
    "y_true_fc, y_pred_fc, pe_fc_all, acc_fc_all = evaluate_two_part_lstm(\n",
    "    X_flood, y_c_flood,\n",
    "    clf_flood_crops_model, clf_flood_crops_scaler,\n",
    "    reg_flood_crops_model, reg_flood_crops_scaler\n",
    ")\n",
    "print(\"\\nFLOOD crops (two-part, all years) — percent error:\", pe_fc_all, \" | accuracy:\", acc_fc_all)\n",
    "\n",
    "# -------------------------\n",
    "# DROUGHT — property (two-part)\n",
    "# -------------------------\n",
    "print(\"\\nDROUGHT property — classifier\")\n",
    "clf_drought_prop_model, clf_drought_prop_scaler, (y_bin_dp_test, p_dp_test) = train_lstm_classifier(\n",
    "    X_drought, y_p_drought,\n",
    "    test_size=0.3, n_epochs=200, batch_size=3,\n",
    "    random_state=123, verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nDROUGHT property — regressor (positive years only)\")\n",
    "reg_drought_prop_model, reg_drought_prop_scaler, (yt_dp_pos, yp_dp_pos, pe_dp_pos, acc_dp_pos) = train_lstm_regressor_positive(\n",
    "    X_drought, y_p_drought,\n",
    "    test_size=0.3, n_epochs=100, batch_size=3,\n",
    "    random_state=123, verbose=1\n",
    ")\n",
    "print(\"DROUGHT property positive-years — percent error:\", pe_dp_pos, \" | accuracy:\", acc_dp_pos)\n",
    "\n",
    "y_true_dp, y_pred_dp, pe_dp_all, acc_dp_all = evaluate_two_part_lstm(\n",
    "    X_drought, y_p_drought,\n",
    "    clf_drought_prop_model, clf_drought_prop_scaler,\n",
    "    reg_drought_prop_model, reg_drought_prop_scaler\n",
    ")\n",
    "print(\"\\nDROUGHT property (two-part, all years) — percent error:\", pe_dp_all, \" | accuracy:\", acc_dp_all)\n",
    "\n",
    "# -------------------------\n",
    "# DROUGHT — crops (two-part)\n",
    "# -------------------------\n",
    "print(\"\\nDROUGHT crops — classifier\")\n",
    "clf_drought_crops_model, clf_drought_crops_scaler, (y_bin_dc_test, p_dc_test) = train_lstm_classifier(\n",
    "    X_drought, y_c_drought,\n",
    "    test_size=0.3, n_epochs=200, batch_size=3,\n",
    "    random_state=123, verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nDROUGHT crops — regressor (positive years only)\")\n",
    "reg_drought_crops_model, reg_drought_crops_scaler, (yt_dc_pos, yp_dc_pos, pe_dc_pos, acc_dc_pos) = train_lstm_regressor_positive(\n",
    "    X_drought, y_c_drought,\n",
    "    test_size=0.3, n_epochs=100, batch_size=3,\n",
    "    random_state=123, verbose=1\n",
    ")\n",
    "print(\"DROUGHT crops positive-years — percent error:\", pe_dc_pos, \" | accuracy:\", acc_dc_pos)\n",
    "\n",
    "y_true_dc, y_pred_dc, pe_dc_all, acc_dc_all = evaluate_two_part_lstm(\n",
    "    X_drought, y_c_drought,\n",
    "    clf_drought_crops_model, clf_drought_crops_scaler,\n",
    "    reg_drought_crops_model, reg_drought_crops_scaler\n",
    ")\n",
    "print(\"\\nDROUGHT crops (two-part, all years) — percent error:\", pe_dc_all, \" | accuracy:\", acc_dc_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0affa59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic plot (two-part prediction vs truth — example: DROUGHT crops)\n",
    "plt.figure()\n",
    "plt.scatter(y_true_dc, y_pred_dc, s=10)\n",
    "plt.xlabel(\"True damage (drought crops)\")\n",
    "plt.ylabel(\"Predicted damage (drought crops)\")\n",
    "plt.title(\"Two-part LSTM — DROUGHT crops (all sequences)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407cb1e",
   "metadata": {},
   "source": [
    "## Future predictions (2024–2059)\n",
    "\n",
    "We use `climate_for_LSTM_1996_2059.csv` to build sequences for years beyond 2023.  \n",
    "Damage columns are merged from historical tables (and set to 0 for future years).\n",
    "\n",
    "Outputs:\n",
    "- `future_LSTM_flood_damage_2024_2059.csv`\n",
    "- `future_LSTM_drought_damage_2024_2059.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c089a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Load climate projections (1996–2059) and historical damage tables (1996–2023)\n",
    "# -------------------------\n",
    "climate_future = pd.read_csv(CLIMATE_FUTURE_CSV)\n",
    "\n",
    "flood_hist   = pd.read_csv(FLOOD_HIST_CSV)\n",
    "drought_hist = pd.read_csv(DROUGHT_HIST_CSV)\n",
    "\n",
    "display(climate_future.head())\n",
    "\n",
    "# -------------------------\n",
    "# Helper to merge climate + historical damages and build sequences\n",
    "# -------------------------\n",
    "def build_sequences_for_future(climate_df, damage_df, seq_len=5):\n",
    "    \"\"\"\n",
    "    climate_df: county, year, precip_ann, runoff_ann (1996–2059)\n",
    "    damage_df : county, year, damage_property, damage_crops (1996–2023)\n",
    "\n",
    "    Returns:\n",
    "        X_all, y_prop_all, y_crops_all, meta_all, future_mask\n",
    "    where future_mask is True for sequences whose target year >= 2024.\n",
    "    \"\"\"\n",
    "    merged = climate_df.merge(\n",
    "        damage_df[[\"county\", \"year\", \"damage_property\", \"damage_crops\"]],\n",
    "        on=[\"county\", \"year\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    merged[[\"damage_property\", \"damage_crops\"]] = merged[\n",
    "        [\"damage_property\", \"damage_crops\"]\n",
    "    ].fillna(0.0)\n",
    "\n",
    "    # reuse your existing function\n",
    "    X_all, y_p_all, y_c_all, meta_all = build_sequences_from_table(\n",
    "        merged, seq_len=seq_len\n",
    "    )\n",
    "\n",
    "    future_mask = meta_all[\"year\"] >= 2024\n",
    "    return X_all, y_p_all, y_c_all, meta_all, future_mask\n",
    "\n",
    "# -------------------------\n",
    "# Two-part prediction helper (no y needed)\n",
    "# -------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "def two_part_predict_only(X,\n",
    "                          clf_model, clf_scaler,\n",
    "                          reg_model, reg_scaler):\n",
    "    \"\"\"\n",
    "    Two-part prediction WITHOUT needing y:\n",
    "      D_hat = P(damage>0) * E[damage | damage>0]\n",
    "    \"\"\"\n",
    "    N, T, F = X.shape\n",
    "\n",
    "    # classifier branch\n",
    "    X_flat = X.reshape(N * T, F)\n",
    "    X_flat_clf = clf_scaler.transform(X_flat)\n",
    "    X_scaled_clf = X_flat_clf.reshape(N, T, F)\n",
    "    p_pos = clf_model.predict(X_scaled_clf).ravel()\n",
    "\n",
    "    # regressor branch\n",
    "    X_flat_reg = reg_scaler.transform(X_flat)\n",
    "    X_scaled_reg = X_flat_reg.reshape(N, T, F)\n",
    "    mu_log = reg_model.predict(X_scaled_reg).ravel()\n",
    "    mu = np.expm1(mu_log)\n",
    "    mu = np.clip(mu, 0, None)\n",
    "\n",
    "    return p_pos * mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c459095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build future sequences for FLOOD and select target years >= 2024\n",
    "X_all_flood, y_p_all_flood, y_c_all_flood, meta_all_flood, future_mask_flood = build_sequences_for_future(\n",
    "    climate_future, flood_hist, seq_len=SEQ_LEN\n",
    ")\n",
    "\n",
    "X_flood_future = X_all_flood[future_mask_flood]\n",
    "meta_flood_future = meta_all_flood[future_mask_flood].reset_index(drop=True)\n",
    "print(\"Flood future target years:\", meta_flood_future[\"year\"].min(), \"-\", meta_flood_future[\"year\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473df7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict FLOOD damages (two-part models)\n",
    "pred_flood_prop_future = two_part_predict_only(\n",
    "    X_flood_future,\n",
    "    clf_flood_prop_model, clf_flood_prop_scaler,\n",
    "    reg_flood_prop_model, reg_flood_prop_scaler\n",
    ")\n",
    "\n",
    "pred_flood_crops_future = two_part_predict_only(\n",
    "    X_flood_future,\n",
    "    clf_flood_crops_model, clf_flood_crops_scaler,\n",
    "    reg_flood_crops_model, reg_flood_crops_scaler\n",
    ")\n",
    "\n",
    "flood_future_pred = meta_flood_future.copy()\n",
    "flood_future_pred[\"flood_property_LSTM\"] = pred_flood_prop_future\n",
    "flood_future_pred[\"flood_crops_LSTM\"]    = pred_flood_crops_future\n",
    "\n",
    "display(flood_future_pred.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_flood = os.path.join(BASE, \"future_LSTM_flood_damage_2024_2059.csv\")\n",
    "flood_future_pred.to_csv(out_flood, index=False)\n",
    "print(\"Saved:\", out_flood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build future sequences for DROUGHT and select target years >= 2024\n",
    "X_all_drought, y_p_all_drought, y_c_all_drought, meta_all_drought, future_mask_drought = build_sequences_for_future(\n",
    "    climate_future, drought_hist, seq_len=SEQ_LEN\n",
    ")\n",
    "\n",
    "X_drought_future = X_all_drought[future_mask_drought]\n",
    "meta_drought_future = meta_all_drought[future_mask_drought].reset_index(drop=True)\n",
    "print(\"Drought future target years:\", meta_drought_future[\"year\"].min(), \"-\", meta_drought_future[\"year\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea9ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict DROUGHT damages (two-part models)\n",
    "pred_drought_prop_future = two_part_predict_only(\n",
    "    X_drought_future,\n",
    "    clf_drought_prop_model, clf_drought_prop_scaler,\n",
    "    reg_drought_prop_model, reg_drought_prop_scaler\n",
    ")\n",
    "\n",
    "pred_drought_crops_future = two_part_predict_only(\n",
    "    X_drought_future,\n",
    "    clf_drought_crops_model, clf_drought_crops_scaler,\n",
    "    reg_drought_crops_model, reg_drought_crops_scaler\n",
    ")\n",
    "\n",
    "drought_future_pred = meta_drought_future.copy()\n",
    "drought_future_pred[\"drought_property_LSTM\"] = pred_drought_prop_future\n",
    "drought_future_pred[\"drought_crops_LSTM\"]    = pred_drought_crops_future\n",
    "\n",
    "display(drought_future_pred.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f31da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_drought = os.path.join(BASE, \"future_LSTM_drought_damage_2024_2059.csv\")\n",
    "drought_future_pred.to_csv(out_drought, index=False)\n",
    "print(\"Saved:\", out_drought)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0a9875",
   "metadata": {},
   "source": [
    "---  \n",
    "### Notes for supplementary materials\n",
    "\n",
    "- Report `SEQ_LEN`, model architecture (LSTM units + dense layers), and the two-part formulation.\n",
    "- Document scaling (StandardScaler fit on training; applied consistently for prediction).\n",
    "- If you want time-aware splits (e.g., train on 1996–2015 and test on 2016–2023), replace the random `train_test_split` with a year-based split using `meta_*[\"year\"]`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
